#!/usr/bin/perl

###############################################################################
# blocklist2rpz-multi.pl - Multi-Source Blocklist to RPZ Converter (Ultimate)
#
# Features:
#   - Supports machine-readable urllist.txt in <category>,<url> format
#   - Automatically categorizes and stores .rpz files in category subdirectories
#   - Warns if a GitHub HTML URL is detected (suggests RAW URL)
#   - Tabular status summary at the end (lists, domains, time per list, total time)
#   - Failed sources are listed in the error log and "Failed sources" section
#   - Optionally writes status report to file (--status-report/-s)
#   - RPZ/domain validation for all generated .rpz files (--validate/-V)
#   - Optionally writes validation report to file (--validation-report)
#   - Wildcard support (--wildcards/-w)
#   - Optional SOA/NS record exclusion (--no-soa/-n)
#   - Flexible logging: logs can be stored in tools/logs/ and excluded from git via .gitignore
#   - Reads list-mappings.csv to use custom filenames for RPZ files
#   - Adds license and source comments from list-mappings.csv to RPZ headers
#   - Change detection using HEAD requests (ETag/Last-Modified) or SHA256 hash
#   - Stores hashes, domains, file sizes, and last_updated in tools/source-hashes.csv for change tracking
#   - Generates SOURCES.md with source overview, including persistent stats
#   - Handles unreachable sources with retry logic (reset hash after 3 failed attempts)
#   - Debug level control (--debug-level=[0|1|2])
#
# -----------------------------------------------------------------------------
# Supported Input Formats:
#   - Defined in @INPUT_FORMATS below (e.g., Hosts, Adblock Plus, Plain Domains, etc.)
#   - Lines starting with # or ; are treated as comments
#   - Invalid or duplicate domains are skipped automatically
#
# -----------------------------------------------------------------------------
# Usage:
#   perl blocklist2rpz-multi.pl [options]
#
# Options:
#   --wildcards, -w               Output wildcard RPZ entries (*.<domain> CNAME .)
#   --output-dir, -d <dir>        Output base directory for RPZ files (default: .)
#   --urllist, -l <file>          File with <category>,<url> per line (CSV format)
#   --list-mappings, -m <file>    File with <url>,<category>,<filename>,<comments> to map URLs to custom RPZ filenames
#   --error-log, -e <file>        Write unreachable or failed sources to this log file
#   --no-soa, -n                  Do not output SOA and NS records in the RPZ file
#   --status-report, -s <file>    Write processing summary to this file
#   --validate, -V                Validate all generated RPZ files for syntax and domain errors
#   --validation-report <file>    Write validation report to this file
#   --debug-level <0|1|2>         Debug level: 0=none, 1=info (default), 2=full debug
#   --help, -h                    Show this help message
#
# -----------------------------------------------------------------------------
# SOURCES.md Overview:
#   The SOURCES.md file provides a user-friendly, regularly updated overview of all
#   available RPZ files generated by this script. Each entry includes:
#
#     - RPZ File URL:   Direct link to the RPZ file for use in Unbound or other RPZ-compatible resolvers
#     - Last Updated:   Timestamp of the last actual content update for this source (based on content change)
#     - Category:       Thematic category (e.g. ads, malware, etc.)
#     - Entries:        Number of domains/entries in the RPZ file
#     - Size:           File size (in bytes or KB)
#     - License:        License type of the source list
#     - File Path:      Relative path to the RPZ file in the repository
#     - Status:         Current status (see definitions below)
#
#   Use the RPZ File URL directly in your DNS resolver configuration.
#
# Status Definitions (used in SOURCES.md and logs):
#   Updated        - Source was fetched and RPZ file was updated with new content
#   No Updates     - Source was checked but no changes detected (ETag, Last-Modified, or hash match)
#   Not Reachable - Source could not be fetched (HTTP error or timeout)
#   Outdated       - Source not checked/updated in over 30 days
#
# -----------------------------------------------------------------------------
# Example:
#   perl $0 -w -d . -l tools/urllist.txt -m tools/list-mappings.csv \
#     -e tools/logs/error.log -s tools/logs/status.txt \
#     --validate --validation-report tools/logs/validation.txt --debug-level=1
#
# -----------------------------------------------------------------------------
# Notes:
#   - .rpz files are stored in category subdirectories (e.g. ads/, malware/, etc.)
#   - Logs are recommended to be stored in tools/logs/ and excluded from git via .gitignore
#   - urllist.txt must use the <category>,<url> format
#   - list-mappings.csv must use the <url>,<category>,<filename>,<comments> format
#   - source-hashes.csv tracks source changes and is versioned in the repository
#
# -----------------------------------------------------------------------------
# Dependencies:
#   - Perl 5.10 or newer
#   - Core modules: strict, warnings, Getopt::Long, POSIX, File::Basename,
#     File::Path, URI, open, Time::Piece, Encode
#   - CPAN modules: LWP::UserAgent, Text::CSV, Digest::SHA, File::Slurp
#
# -----------------------------------------------------------------------------
# Author: ummeegge, with community contributions
# Contact: twitOne@protonmail.com
# Version: 0.4.4
# Last Modified: 2025-07-01
# License: GNU General Public License v3.0 (GPLv3)
#   See LICENSE file for full license text.
#
###############################################################################

use strict;
use warnings;
use LWP::UserAgent;
use Getopt::Long;
use POSIX qw(strftime);
use File::Basename;
use File::Path qw(make_path);
use URI;
use open ':std', ':encoding(UTF-8)';
use Text::CSV;
use Digest::SHA qw(sha256_hex);
use File::Slurp;
use Time::Piece;
use Encode;

# Input format definitions for blocklist conversion to RPZ
# This array defines supported input formats for parsing blocklist entries.
# Each format includes:
# - name: Descriptive name for logging and debugging.
# - regex: Regular expression to match the input line and capture the domain.
# - group: Capture group index containing the domain (usually 1).
# To add a new format, append a new hash with these fields.
# Example for a custom format: { name => 'Custom', regex => qr/^([^\s]+?\.[^\s]+?)#block/, group => 1 }
my @INPUT_FORMATS = (
	{
		name   => 'Hosts',                           # e.g., "0.0.0.0 example.com"
		regex  => qr/^\s*(?:0\.0\.0\.0|127\.0\.0\.1)\s+([^\s]+)/,
		group  => 1,
	},
	{
		name   => 'Adblock Plus',                    # e.g., "||example.com^"
		regex  => qr/^\|\|([^\^]+)\^/,
		group  => 1,
	},
	{
		name   => 'Plain Domain',                    # e.g., "example.com" or "*.example.com"
		regex  => qr/^(\*?[^\s]+?\.[^\s]+?)\s*(?:[#;].*)?$/,
		group  => 1,
	},
	{
		name   => 'CSV/Tab-separated',               # e.g., "example.com,category" or "example.com\tcategory"
		regex  => qr/^(\*?[^\s]+?\.[^\s]+?)[,\t]/,
		group  => 1,
	},
	{
		name   => 'URL',                             # e.g., "https://example.com/"
		regex  => qr{^https?://(\*?[^\s]+?\.[^\s]+?)(?:/|$)},
		group  => 1,
	},
	# Add new formats here, e.g.:
	# {
	#     name   => 'Custom Block',                # e.g., "example.com#block"
	#     regex  => qr/^([^\s]+?\.[^\s]+?)#block/,
	#     group  => 1,
	# },
);

# Constants
use constant {
	HASH_FILE      => 'tools/source-hashes.csv',
	SOURCES_MD     => 'SOURCES.md',
	STATUS_UPDATED => 'Updated',
	STATUS_NO_UPDATES => 'No Updates',
	STATUS_NOT_REACHABLE => 'Not Reachable',
	STATUS_OUTDATED => 'Outdated',
	MAX_FAILED_ATTEMPTS => 3,
	REPO_URL_BASE => 'https://raw.githubusercontent.com/twitOne/RPZ-Blocklists/main/'
};

# Command-line option variables
my $wildcards         = 0;
my $output_dir        = '.'; # Output directly to category subdirectories in main directory
my $help              = 0;
my $urllist           = '';
my $list_mappings     = '';
my $error_log         = '';
my $no_soa            = 0;
my $status_report     = '';
my $validate          = 0;
my $validation_report = '';
my $debug_level       = 1; # Debug level: 0=none, 1=info (default), 2=full debug

GetOptions(
	'wildcards|w'           => \$wildcards,
	'output-dir|d=s'        => \$output_dir,
	'urllist|l=s'           => \$urllist,
	'list-mappings|m=s'     => \$list_mappings,
	'error-log|e=s'         => \$error_log,
	'no-soa|n'              => \$no_soa,
	'status-report|s=s'     => \$status_report,
	'validate|V'            => \$validate,
	'validation-report=s'   => \$validation_report,
	'debug-level=i'         => \$debug_level,
	'help|h'                => \$help,
) or die "Error in command line arguments. Use --help for usage.\n";

if ($help or (!$urllist && !@ARGV)) {
	print <<USAGE;
Usage: $0 [options]
Options:
	--wildcards, -w             Output wildcard RPZ entries (*.<domain> CNAME .)
	--output-dir, -d <dir>      Output directory for RPZ files (default: .)
	--urllist, -l <file>        File with category,url per line (see README)
	--list-mappings, -m <file>  File with url,category,filename,comments to map URLs to custom RPZ filenames
	--error-log, -e <file>      Write unreachable or failed sources to this log file
	--no-soa, -n                Do not output SOA and NS records in the RPZ file
	--status-report, -s <file>  Write processing summary to this file
	--validate, -V              Validate all generated RPZ files for syntax and domain errors
	--validation-report <file>  Write validation report to this file
	--debug-level <0|1|2>       Debug level: 0=none, 1=info (default), 2=full debug
	--help, -h                  Show this help message
Example:
	perl $0 -w -d . -l tools/urllist.txt -m tools/list-mappings.csv \
	-e tools/logs/error.log -s tools/logs/status.txt \
	--validate --validation-report tools/logs/validation.txt --debug-level=1
USAGE
	exit 0;
}

# Prepare HTTP user agent for downloads
my $ua = LWP::UserAgent->new(timeout => 20);

# Logging function
sub log_message {
	my ($level, $message) = @_;
	return if ($level eq 'DEBUG' && $debug_level < 2) || ($level eq 'INFO' && $debug_level < 1);
	print "$level: $message\n"; # Only output to STDOUT
}

# Format file size with appropriate unit
sub format_file_size {
	my ($size_kb) = @_;
	my $size_bytes = $size_kb * 1024;
	return sprintf("%.0f B", $size_bytes) if $size_bytes < 1024;
	return sprintf("%.1f KB", $size_bytes / 1024) if $size_bytes < 1024 * 1024;
	return sprintf("%.1f MB", $size_bytes / (1024 * 1024)) if $size_bytes < 1024 * 1024 * 1024;
	return sprintf("%.1f GB", $size_bytes / (1024 * 1024 * 1024));
}

# Convert time to ISO format
sub convert_to_iso {
	my ($time_str) = @_;
	return $time_str if $time_str =~ /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z$/; # Already ISO
	my $t;
	eval {
		$t = Time::Piece->strptime($time_str, "%a, %d %b %Y %H:%M:%S %Z");
	} or eval {
		$t = Time::Piece->strptime($time_str, "%a, %d %b %Y %H:%M:%S GMT");
	};
	return $t ? $t->strftime("%Y-%m-%dT%H:%M:%SZ") : $time_str;
}

# Format relative time for SOURCES.md
sub format_relative_time {
	my ($time_str, $last_checked) = @_;
	return 'Unknown' unless $time_str && $time_str ne 'Unknown';
	my $last_updated;
	eval {
		$last_updated = Time::Piece->strptime($time_str, "%Y-%m-%dT%H:%M:%SZ");
	} or eval {
		$last_updated = Time::Piece->strptime($time_str, "%a, %d %b %Y %H:%M:%S %Z");
	} or eval {
		$last_updated = Time::Piece->strptime($time_str, "%a, %d %b %Y %H:%M:%S GMT");
	};
	if ($last_updated) {
		my $time_diff = gmtime() - $last_updated;
		return '30+ Days' if $time_diff > 30 * 86400;
		return sprintf("%d Seconds", $time_diff) if $time_diff < 60;
		return sprintf("%d Minutes", int($time_diff / 60)) if $time_diff < 3600;
		return sprintf("%d Hours", int($time_diff / 3600)) if $time_diff < 86400;
		return sprintf("%d Days", int($time_diff / 86400));
	}
	log_message('WARNING', "Invalid time format: $time_str, falling back to last_checked");
	return 'Unknown' unless $last_checked;
	my $last_checked_time;
	eval {
		$last_checked_time = Time::Piece->strptime($last_checked, "%Y-%m-%dT%H:%M:%SZ");
	};
	return 'Unknown' unless $last_checked_time;
	my $time_diff = gmtime() - $last_checked_time;
	return sprintf("%d Seconds", $time_diff) if $time_diff < 60;
	return sprintf("%d Minutes", int($time_diff / 60)) if $time_diff < 3600;
	return sprintf("%d Hours", int($time_diff / 3600)) if $time_diff < 86400;
	return sprintf("%d Days", int($time_diff / 86400));
}

# Open file with error handling and create directories if needed
sub open_file {
	my ($file, $mode) = @_;
	my $dir = dirname($file); # Extract directory path
	make_path($dir) unless -d $dir; # Create directory if it doesn't exist
	open my $fh, $mode, $file or die "Cannot open $file: $!\n";
	return $fh;
}

# Initialize list stats
sub initialize_list_stats {
	my ($source, $category, $filename, $entry_count, $list_start, $skip_update, $file_size, $hashes_ref, $url_to_filename_ref) = @_;
	my $last_checked = strftime("%Y-%m-%dT%H:%M:%SZ", gmtime);
	return {
		domains     => $entry_count // ($hashes_ref->{$source}{domains} || 0),
		error       => 0,
		time        => time - $list_start,
		skipped     => $skip_update,
		status      => $skip_update ? STATUS_NO_UPDATES : STATUS_UPDATED,
		file_size   => $file_size // ($hashes_ref->{$source}{file_size} || 0),
		file_path   => "$category/$filename",
		last_updated => convert_to_iso($hashes_ref->{$source}{last_updated} || $hashes_ref->{$source}{last_modified} || $last_checked),
		license     => $url_to_filename_ref->{$source}{comments} ? ($url_to_filename_ref->{$source}{comments} =~ /License: ([^;]+)/ ? $1 : 'Unknown') : 'Unknown',
	};
}

# Initialize hash entry
sub initialize_hash_entry {
	my ($source, $last_checked, $row) = @_;
	return {
		hash           => $row ? ($row->[1] || '') : '',
		etag           => $row ? ($row->[2] || '') : '',
		last_modified  => $row ? ($row->[3] || '') : '',
		last_checked   => $row ? ($row->[4] || '') : ($last_checked || ''),
		failed_attempts => $row ? ($row->[5] || 0) : 0,
		domains        => $row ? ($row->[6] || 0) : 0,
		file_size      => $row ? ($row->[7] || 0) : 0,
		filename       => $row ? ($row->[8] || '') : '',
		last_updated   => $row ? convert_to_iso($row->[9] || $row->[3] || $row->[4] || '') : '',
		serial_counter => $row ? ($row->[10] || 0) : 0
	};
}

# Handle failed attempt for a source
sub handle_failed_attempt {
	my ($source, $msg, $err_fh, $list_start, $category, $filename, $hashes_ref, $url_to_filename_ref, $list_stats_ref) = @_;
	warn $msg;
	print $err_fh "$msg\n" if $err_fh;
	$hashes_ref->{$source}{failed_attempts}++;
	if ($hashes_ref->{$source}{failed_attempts} >= MAX_FAILED_ATTEMPTS) {
		$hashes_ref->{$source}{hash} = '';
		$hashes_ref->{$source}{etag} = '';
		$hashes_ref->{$source}{last_modified} = '';
		$hashes_ref->{$source}{domains} = 0;
		$hashes_ref->{$source}{file_size} = 0;
		$hashes_ref->{$source}{last_updated} = '';
		print $err_fh "Reset hash for $source after " . MAX_FAILED_ATTEMPTS . " failed attempts\n" if $err_fh;
	}
	$hashes_ref->{$source}{last_checked} = strftime("%Y-%m-%dT%H:%M:%SZ", gmtime);
	$list_stats_ref->{$source} = initialize_list_stats($source, $category, $filename, undef, $list_start, 0, undef, $hashes_ref, $url_to_filename_ref);
	$list_stats_ref->{$source}{error} = 1;
	$list_stats_ref->{$source}{status} = STATUS_NOT_REACHABLE;
	return 1; # Indicate failure
}

# Open error log file if requested
my $err_fh;
if ($error_log) {
	$err_fh = open_file($error_log, '>:encoding(UTF-8)');
	print $err_fh "=== Blocklist2RPZ Run at " . localtime() . " ===\n";
}

# Read list mappings from list-mappings.csv
my %url_to_filename;
my %filename_to_url; # Track filename to detect duplicates
if ($list_mappings) {
	my $csv = Text::CSV->new({ binary => 1, sep_char => ',', auto_diag => 1 });
	my $mfh = open_file($list_mappings, '<:encoding(utf8)');
	my $line_num = 0;
	while (my $row = $csv->getline($mfh)) {
		$line_num++;
		log_message('DEBUG', "Processing row $line_num: @$row") if $debug_level >= 2;
		next unless @$row >= 3;
		my ($url, $category, $filename, $comments) = @$row;
		log_message('DEBUG', "Parsed: URL=$url, Category=$category, Filename=$filename, Comments=$comments") if $debug_level >= 2;
		if ($url_to_filename{$url}) {
			log_message('WARNING', "Duplicate URL in list-mappings.csv: $url, keeping first entry ($url_to_filename{$url}{filename})");
			next;
		}
		if ($filename_to_url{$filename}) {
			log_message('WARNING', "Duplicate filename in list-mappings.csv: $filename for URL $url, already used by $filename_to_url{$filename}");
			next;
		}
		$url_to_filename{$url} = { category => $category, filename => $filename, comments => $comments };
		$filename_to_url{$filename} = $url;
	}
	close $mfh;
}

# Load or initialize hash storage
my %hashes;
if (-f HASH_FILE) {
	my $csv = Text::CSV->new({ binary => 1, sep_char => ',', auto_diag => 1 });
	my $hfh = open_file(HASH_FILE, '<:encoding(utf8)');
	$csv->getline($hfh); # Skip header
	while (my $row = $csv->getline($hfh)) {
		next unless @$row >= 9; # Ensure compatibility with old format
		my ($url) = @$row;
		$hashes{$url} = initialize_hash_entry($url, undef, $row);
	}
	close $hfh;
}

# Read categorized sources from urllist.txt
my @categorized_sources;
my %processed_urls; # Track processed URLs to avoid duplicates
if ($urllist) {
	my $ufh = open_file($urllist, '<');
	while (my $line = <$ufh>) {
		chomp $line;
		$line =~ s/^\s+|\s+$//g;
		next if $line =~ /^\s*(#.*)?$/;
		if ($line =~ /^([a-zA-Z0-9_-]+),(https?:\/\/.+)$/) {
			my ($cat, $url) = ($1, $2);
			if ($processed_urls{$url}++) {
				log_message('WARNING', "Duplicate URL in urllist.txt: $url, skipping");
				next;
			}
			push @categorized_sources, { category => $cat, url => $url };
		}
	}
	close $ufh;
}

my %list_stats;
my %validated_files; # Track validated files to prevent duplicates
my ($ok, $skipped, $failed, $total_domains, $head_requests, $full_downloads, $total_time) = (0, 0, 0, 0, 0, 0, time);

foreach my $entry (@categorized_sources) {
	my $category = $entry->{category};
	my $source = $entry->{url};
	my $list_start = time;  # Start time for specific source
	log_message('INFO', "Processing source: $source (Category: $category)");
	my ($content, $new_hash, $current_etag, $current_last_modified, $skip_update) = ('', '', '', '', 0);
	my $last_checked = strftime("%Y-%m-%dT%H:%M:%SZ", gmtime);

	# Initialize hash entry if not exists
	$hashes{$source} ||= initialize_hash_entry($source, $last_checked);

	# Define filename and output_file early
	my $filename = $url_to_filename{$source}{filename} || basename($source) . '.rpz';
	$filename =~ s/\.[a-z]+$/.rpz/i;
	my $output_file = "$output_dir/$category/$filename";
	my $output_dir_for_cat = "$output_dir/$category";
	make_path($output_dir_for_cat) unless -d $output_dir_for_cat;

	# Check for filename changes
	if (defined $hashes{$source}{filename} && $hashes{$source}{filename} ne $filename && $hashes{$source}{filename} ne '') {
		log_message('INFO', "Filename for $source changed from $hashes{$source}{filename} to $filename, forcing generation of $output_file");
		$skip_update = 0; # Force generation
		my $old_output_file = "$output_dir/$category/$hashes{$source}{filename}";
		if (-e $old_output_file) {
			log_message('INFO', "Removing outdated RPZ file: $old_output_file");
			unlink $old_output_file or log_message('WARNING', "Failed to remove $old_output_file: $!");
		}
		$hashes{$source}{filename} = $filename;
	}

	# Check for GitHub HTML URLs
	if ($source =~ m{^https?://(?:www\.)?github\.com/.*?(?:blob|raw)/}) {
		warn "Possible GitHub HTML URL detected: $source\n";
		warn "Use raw.githubusercontent.com instead\n";
		print $err_fh "Invalid URL (GitHub HTML): $source\n" if $err_fh;
		$failed++ if handle_failed_attempt($source, "Invalid URL (GitHub HTML): $source", $err_fh, $list_start, $category, $filename, \%hashes, \%url_to_filename, \%list_stats);
		next;
	}

	# ETag/Last-Modified check
	$head_requests++;
	my $head_resp = $ua->head($source);
	if ($head_resp->is_success) {
		$current_etag = $head_resp->header('ETag') || '';
		$current_last_modified = $head_resp->header('Last-Modified') || '';
		log_message('DEBUG', "ETag for $source: \"$current_etag\"") if $current_etag && $debug_level >= 2;
		log_message('DEBUG', "Last-Modified for $source: $current_last_modified") if $current_last_modified && $debug_level >= 2;
		log_message('DEBUG', "Stored ETag: \"$hashes{$source}{etag}\", Stored Last-Modified: $hashes{$source}{last_modified}") if ($hashes{$source}{etag} || $hashes{$source}{last_modified}) && $debug_level >= 2;
		# Force update if stored hash is invalid (e.g., all zeros or empty)
		if ($hashes{$source}{hash} eq '' || $hashes{$source}{hash} =~ /^0+$/) {
			$skip_update = 0;
			log_message('DEBUG', "Forcing update for $source: Invalid stored hash ($hashes{$source}{hash})") if $debug_level >= 2;
		} elsif ($current_etag && $hashes{$source}{etag} && $current_etag eq $hashes{$source}{etag}) {
			$skip_update = 1;
			log_message('DEBUG', "Skipping $source: ETag unchanged") if $debug_level >= 2;
		} elsif ($current_last_modified && $hashes{$source}{last_modified} && $current_last_modified eq $hashes{$source}{last_modified}) {
			$skip_update = 1;
			log_message('DEBUG', "Skipping $source: Last-Modified unchanged") if $debug_level >= 2;
		}
	} else {
		$failed++ if handle_failed_attempt($source, "HEAD request failed for $source: " . $head_resp->status_line, $err_fh, $list_start, $category, $filename, \%hashes, \%url_to_filename, \%list_stats);
		next;
	}

	# Check if RPZ file exists to force generation if missing
	if (! -e $output_file) {
		log_message('INFO', "RPZ file $output_file does not exist, forcing generation for URL $source");
		$skip_update = 0; # Force generation by resetting skip_update
	}

	# Download and hash check
	unless ($skip_update) {
		$full_downloads++;
		my $resp = $ua->get($source);
		unless ($resp->is_success) {
			$failed++ if handle_failed_attempt($source, "Could not fetch $source: " . $resp->status_line, $err_fh, $list_start, $category, $filename, \%hashes, \%url_to_filename, \%list_stats);
			next;
		}
		$content = $resp->decoded_content;
		$content = Encode::encode('UTF-8', $content);
		$new_hash = sha256_hex($content);
		log_message('DEBUG', "New hash for $source: $new_hash") if $debug_level >= 2;
		log_message('DEBUG', "Stored hash: $hashes{$source}{hash}") if $hashes{$source}{hash} && $debug_level >= 2;
		if ($hashes{$source}{hash} && $new_hash eq $hashes{$source}{hash} && $current_etag eq $hashes{$source}{etag}) {
			$skip_update = 1;
			log_message('DEBUG', "Skipping $source: Hash and ETag unchanged") if $debug_level >= 2;
		} else {
			$hashes{$source}{hash} = $new_hash;
			$hashes{$source}{etag} = $current_etag;
			$hashes{$source}{last_modified} = $current_last_modified || strftime("%Y-%m-%dT%H:%M:%SZ", gmtime);
			$hashes{$source}{failed_attempts} = 0;
			$hashes{$source}{filename} = $filename;
			$hashes{$source}{serial_counter}++; # Inkrementiere hier
			log_message('DEBUG', "Incremented serial_counter for $source to $hashes{$source}{serial_counter}") if $debug_level >= 2;
		}
		$hashes{$source}{last_checked} = $last_checked;
	}

	# Convert to RPZ format
	my $entry_count = 0;
	my $file_size = 0;
	my $file_path = "$category/$filename";
	unless ($skip_update) {
		# Check for date change and reset serial_counter if needed
		my $current_date = strftime("%Y%m%d", gmtime);
		my $last_updated = $hashes{$source}{last_updated} || '';
		my $last_date = '';
		if ($last_updated =~ /^(\d{4})(\d{2})(\d{2})/) {
			$last_date = "$1$2$3";
		}
		if ($last_date && $last_date ne $current_date) {
			$hashes{$source}{serial_counter} = 1;
			log_message('DEBUG', "Reset serial_counter for $source to 1 due to date change") if $debug_level >= 2;
		}
		my ($rpz_data, $count) = convert_blocklist_to_rpz($content, $source, $wildcards, $no_soa, $url_to_filename{$source}{comments});
		$entry_count = $count;
		log_message('DEBUG', "Checking if output file exists: $output_file") if $debug_level >= 2;
		my $old_serial_counter = $hashes{$source}{serial_counter}; # Speichere alten Counter
		log_message('DEBUG', "Before processing: serial_counter for $source = $old_serial_counter") if $debug_level >= 2;
		if (-f $output_file) {
			my $existing_content = read_file($output_file, binmode => ':raw') || '';
			$existing_content =~ s/[^\x00-\x7F]//g; # Remove non-ASCII characters
			my $existing_hash = sha256_hex($existing_content);
			my $clean_rpz_data = $rpz_data;
			$clean_rpz_data =~ s/[^\x00-\x7F]//g; # Remove non-ASCII characters
			my $new_content_hash = sha256_hex($clean_rpz_data);
			if ($existing_hash eq $new_content_hash) {
				log_message('INFO', "Output file $output_file unchanged, skipping write");
				$skip_update = 1;
				$file_size = (-s $output_file) / 1024;
				$file_path = "$category/$filename";
				$hashes{$source}{domains} = $entry_count;
				$hashes{$source}{file_size} = $file_size;
				log_message('DEBUG', "Keeping serial_counter for $source at $hashes{$source}{serial_counter} despite unchanged content") if $debug_level >= 2;
			} else {
				log_message('WARNING', "Output file $output_file exists but content changed, overwriting");
			}
		}
		unless ($skip_update) {
			my $clean_rpz_data = $rpz_data;
			$clean_rpz_data =~ s/\x{FEFF}//g; # Remove BOM
			$clean_rpz_data =~ s/[^\x00-\x7F]//g; # Remove non-ASCII characters
			my $current_date = strftime("%Y%m%d", gmtime);
			my $serial = sprintf("%s%02d", $current_date, $hashes{$source}{serial_counter});
			$clean_rpz_data =~ s/@ SOA localhost\. root\.localhost\. \d+/@ SOA localhost. root.localhost. $serial/;
			my $fh = open_file($output_file, '>:raw');
			print $fh $clean_rpz_data;
			close $fh;
			$file_size = (-s $output_file) / 1024;
			$file_path = "$category/$filename";
			log_message('INFO', sprintf("Generated %s: %d entries, %.1f KB", $output_file, $entry_count, $file_size));
			$hashes{$source}{domains} = $entry_count;
			$hashes{$source}{file_size} = $file_size;
			$hashes{$source}{filename} = $filename;
			$hashes{$source}{last_updated} = strftime("%Y-%m-%dT%H:%M:%SZ", gmtime);
		}
	}
	$list_stats{$source} = initialize_list_stats($source, $category, $filename, $entry_count, $list_start, $skip_update, $file_size, \%hashes, \%url_to_filename);
	$ok++ unless $skip_update;
	# Validation
	if ($validate && !$skip_update && !$validated_files{$output_file}) {
		log_message('INFO', "Validating $output_file...");
		my $validation_output = validate_rpz_file($output_file);
		if ($validation_report) {
			my $vfh = open_file($validation_report, '>>:encoding(UTF-8)');
			print $vfh $validation_output;
			close $vfh;
		} else {
			print $validation_output;
		}
		$validated_files{$output_file} = 1;
	}

	$total_domains += $entry_count;
}

# Write status file
if ($status_report) {
	my $status_fh = open_file($status_report, '>:encoding(UTF-8)');
	$total_time = time - $total_time;
	printf $status_fh "Processed %d sources: %d OK, %d Skipped, %d Failed, %d total domains in %.2f seconds\n", scalar(@categorized_sources), $ok, $skipped, $failed, $total_domains, $total_time;
	printf $status_fh "HEAD requests: %d, Full downloads: %d\n\n", $head_requests, $full_downloads;
	print $status_fh "=" x 80 . "\n";
	print $status_fh sprintf("%-50s %-11s %-14s %s\n", "List", "Domains", "Time (s)", "Status");
	print $status_fh "-" x 80 . "\n";
	foreach my $source (sort keys %list_stats) {
		my $list_name = $url_to_filename{$source}{filename} || basename(URI->new($source)->path) || URI->new($source)->host;
		my $status = $list_stats{$source}{status};
		if ($status eq STATUS_NO_UPDATES) {
			my $last_updated;
			eval {
				$last_updated = $hashes{$source}{last_updated} ? Time::Piece->strptime($hashes{$source}{last_updated}, "%Y-%m-%dT%H:%M:%SZ") : gmtime();
			};
			if ($last_updated && (gmtime() - $last_updated) > 30 * 86400) {
				$status = STATUS_OUTDATED;
				$list_stats{$source}{status} = STATUS_OUTDATED;
			}
		}
		printf $status_fh "%-50s %-11d %-14.2f %s\n", $list_name, $list_stats{$source}{domains}, $list_stats{$source}{time}, $status;
	}
	print $status_fh "\nFailed sources:\n" if $failed;
	foreach my $source (sort keys %list_stats) {
		print $status_fh "$source\n" if $list_stats{$source}{status} eq STATUS_NOT_REACHABLE;
	}
	my %status_counts;
	$status_counts{STATUS_UPDATED}       = 0;
	$status_counts{STATUS_NO_UPDATES}    = 0;
	$status_counts{STATUS_NOT_REACHABLE} = 0;
	$status_counts{STATUS_OUTDATED}      = 0;
	$status_counts{$list_stats{$_}{status}}++ for keys %list_stats;
	print $status_fh "\nStatus Summary:\n";
	print $status_fh "-" x 80 . "\n";
	for my $status (STATUS_UPDATED, STATUS_NO_UPDATES, STATUS_NOT_REACHABLE, STATUS_OUTDATED) {
		printf $status_fh "%-20s %d\n", $status, ($status_counts{$status} // 0);
	}
	print $status_fh "-" x 80 . "\n";
	close $status_fh;
}

# Clean up old RPZ files not referenced in urllist.txt or list-mappings.csv
sub cleanup_old_rpz_files {
	my ($output_dir, $url_to_filename, $categorized_sources) = @_;
	my %expected_files;

	foreach my $entry (@$categorized_sources) {
		my $url = $entry->{url};
		my $category = $entry->{category};
		my $filename = $url_to_filename->{$url}{filename} || basename(URI->new($url)->path) . '.rpz';
		$filename =~ s/\.[a-z]+$/.rpz/i;
		$expected_files{"$output_dir/$category/$filename"} = 1;
	}

	for my $category_dir (glob "$output_dir/*") {
		next unless -d $category_dir;
		for my $file (glob "$category_dir/*.rpz") {
			unless ($expected_files{$file}) {
				log_message('INFO', "Removing outdated RPZ file: $file");
				unlink $file or warn "Failed to delete $file: $!\n";
			}
		}
	}
}

# Call cleanup function after processing sources
cleanup_old_rpz_files($output_dir, \%url_to_filename, \@categorized_sources);

# Save updated hashes
my $csv = Text::CSV->new({ binary => 1, sep_char => ',', auto_diag => 1 });
my $hfh = open_file(HASH_FILE, '>:encoding(utf8)');
$csv->print($hfh, ['source', 'hash', 'etag', 'last_modified', 'last_checked', 'failed_attempts', 'domains', 'file_size', 'filename', 'last_updated', 'serial_counter']);
print $hfh "\n";
foreach my $url (sort keys %hashes) {
	$csv->print($hfh, [
		$url,
		$hashes{$url}{hash} || '',
		$hashes{$url}{etag} || '',
		$hashes{$url}{last_modified} || '',
		$hashes{$url}{last_checked} || '',
		$hashes{$url}{failed_attempts} || 0,
		$hashes{$url}{domains} || 0,
		$hashes{$url}{file_size} || 0,
		$hashes{$url}{filename} || '',
		convert_to_iso($hashes{$url}{last_updated} || ''),
		$hashes{$url}{serial_counter} || 0
	]);
	print $hfh "\n";
}
close $hfh;

# Generate SOURCES.md
my $md_fh = open_file(SOURCES_MD, '>:encoding(utf8)');
print $md_fh "# Blocklist Sources Overview\n\n";
print $md_fh "| RPZ File URL | Last Updated | Category | Entries | Size | License | Source URL | Status |\n";
print $md_fh "|--------------|--------------|----------|---------|------|---------|------------|--------|\n";

foreach my $entry (@categorized_sources) {
    my $url      = $entry->{url};
    my $category = $entry->{category};

    # Use persistent domains and file_size from %hashes
    my $domains   = $hashes{$url}{domains}    // 0;
    my $file_size = $hashes{$url}{file_size}  // 0;

    # Determine last updated time from hashes (prefer last_modified)
    my $last_updated = $hashes{$url}{last_modified} || $hashes{$url}{last_updated} || $hashes{$url}{last_checked} || 'Unknown';

    # Start with status from list_stats if available, else fallback
    my $status = $list_stats{$url}{status} // 'Not Processed';

    # Override status to Outdated if last_updated is older than 30 days
    if ($last_updated && $last_updated ne 'Unknown') {
        my $t;
        eval {
            $t = Time::Piece->strptime($last_updated, "%a, %d %b %Y %H:%M:%S %Z");
        } or eval {
            $t = Time::Piece->strptime($last_updated, "%a, %d %b %Y %H:%M:%S GMT");
        } or eval {
            $t = Time::Piece->strptime($last_updated, "%Y-%m-%dT%H:%M:%SZ");
        };
        if ($t && (gmtime() - $t) > 30 * 86400) {
            $status = STATUS_OUTDATED;
        }
    }

    my $relative_time = format_relative_time($last_updated, $hashes{$url}{last_checked});

    my $filename  = $url_to_filename{$url}{filename} || basename(URI->new($url)->path) . '.rpz';
    $filename     =~ s/\.[a-z]+$/.rpz/i;
    my $file_path = "$category/$filename";
    my $rpz_url   = "[$file_path](" . REPO_URL_BASE . "$file_path)";

    my $license = $url_to_filename{$url}{comments} ? ($url_to_filename{$url}{comments} =~ /License: ([^;]+)/ ? $1 : 'Unknown') : 'Unknown';
    $license =~ s/\s*\(.+?\)|\s*License\s*//gi;
    $license = 'None specified' if $license eq 'Unknown' || $license =~ /^\s*$/;

    my $source_name = $url_to_filename{$url}{comments} ? ($url_to_filename{$url}{comments} =~ /Source: ([^\(]+)/ ? $1 : 'Unknown') : 'Unknown';
    $source_name =~ s/\s+$//;
    my $source_url = "[$source_name]($url)";

    print $md_fh "| $rpz_url | $relative_time | $category | $domains | " . format_file_size($file_size) . " | $license | $source_url | $status |\n";
}

print $md_fh "\n## Status Definitions\n";
print $md_fh "- **" . STATUS_UPDATED . "**: Source was fetched and RPZ file was updated with new content.\n";
print $md_fh "- **" . STATUS_NO_UPDATES . "**: Source was checked but no changes detected (ETag, Last-Modified, or hash match).\n";
print $md_fh "- **" . STATUS_NOT_REACHABLE . "**: Source could not be fetched (HTTP error or timeout).\n";
print $md_fh "- **" . STATUS_OUTDATED . "**: Source not updated in over 30 days.\n";
close $md_fh;

# Close error log
close $err_fh if $err_fh;

# Convert blocklist to RPZ format
sub convert_blocklist_to_rpz {
	my ($content, $source, $wildcards, $no_soa, $comments) = @_;
	my %seen;
	my $entry_count = 0;
	my $rpz_data = '';
	unless ($no_soa) {
		my $current_date = strftime("%Y%m%d", gmtime);
		my $serial = sprintf("%s%02d", $current_date, $hashes{$source}{serial_counter});
		$rpz_data .= "\$TTL 300\n";
		$rpz_data .= "@ SOA localhost. root.localhost. $serial 43200 3600 86400 300\n";
		$rpz_data .= "  NS  localhost.\n";
	}
	$rpz_data .= ";\n";
	$rpz_data .= "; Generated by blocklist2rpz-multi.pl on " . localtime() . "\n";
	$rpz_data .= "; Source URL: $source\n";
	$rpz_data .= ";\n";
	$rpz_data .= "; $comments\n" if $comments;
	$rpz_data .= ";\n";
	$rpz_data .= "; Converted by: blocklist2rpz-multi (Perl script)\n";
	$rpz_data .= "; Source: $source\n";
	$rpz_data .= "; Wildcards: " . ($wildcards ? "enabled" : "disabled") . "\n";
	$rpz_data .= "; SOA/NS records: " . ($no_soa ? "disabled" : "enabled") . "\n";
	$rpz_data .= "; Number of entries: $entry_count\n";
	$rpz_data .= "; Conversion date: " . localtime() . "\n";
	$rpz_data .= "; ======================\n";
	$rpz_data .= ";\n";
	my @domains;
	foreach my $line (split /\n/, $content) {
		chomp $line;
		my $orig_line = $line;
		$line =~ s/\r$//;
		$line =~ s/^\s+|\s+$//g;
		if ($line =~ /^\s*[#;!]/) {
			$rpz_data .= "; $line\n";
			next;
		}
		next if $line =~ /^\s*$/;
		my $domain;
		foreach my $format (@INPUT_FORMATS) {
			if ($line =~ $format->{regex}) {
				$domain = $1;
				log_message('DEBUG', "Matched format $format->{name} for line: $orig_line, extracted domain: $domain") if $debug_level >= 2;
				last;
			}
		}
		if (!$domain && $debug_level >= 2) {
			log_message('DEBUG', "No format matched for line: $orig_line");
		}
		next unless $domain;
		$domain =~ s/^\*\.//;
		if (!is_valid_domain($domain)) {
			log_message('DEBUG', "Domain rejected by is_valid_domain: $domain (from line: $orig_line)") if $debug_level >= 2;
			next;
		}
		next if $seen{$domain}++;
		$rpz_data .= "$domain CNAME .\n";
		$rpz_data .= "*.$domain CNAME .\n" if $wildcards;
		push @domains, "$domain";
		$entry_count++;
	}
	if ($entry_count > 0) {
		log_message('DEBUG', "First 10 domains for $source:\n" . join("\n", @domains[0..($entry_count < 10 ? $entry_count-1 : 9)]));
	} else {
		log_message('DEBUG', "No valid domains for $source");
	}
	$rpz_data =~ s/Number of entries: \d+/Number of entries: $entry_count/;
	return ($rpz_data, $entry_count);
}

# Validate domain format
sub is_valid_domain {
	my $d = shift;
	return 0 if $d =~ /^\d+\.\d+\.\d+\.\d+$/; # IPv4
	return 0 if $d =~ /^\[?[a-fA-F0-9:.]+\]?$/; # IPv6
	return 0 unless $d =~ /^(?:\*\.)?([a-zA-Z0-9-]+\.)+[a-zA-Z]{2,}$/;
	return 1;
}

# Validate RPZ file syntax
sub validate_rpz_file {
	my ($file) = @_;
	my $output = "Validating $file...\n";
	my $fh = open_file($file, '<');
	my $line_num = 0;
	while (my $line = <$fh>) {
		$line_num++;
		chomp $line;
		next if $line =~ /^\s*(;.*)?$/;  # Skip comments
		next if $line =~ /^\$TTL/;       # Skip TTL directives
		next if $line =~ /^@/ && !$no_soa;  # Allow SOA entries
		next if $line =~ /^\s*NS\s+localhost\.$/ && !$no_soa;  # Allow NS entries
		unless ($line =~ /^[a-zA-Z0-9\-\*\.]+\s+CNAME\s+\.$/) {
			$output .= "Invalid RPZ entry at line $line_num: $line\n";
		}
	}
	close $fh;
	$output .= "Validation complete for $file\n";
	return $output;
}

exit 0;